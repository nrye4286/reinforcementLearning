{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1s_Sv6iM3lvs4CbvPIi3uyJIeriFuUdaU","authorship_tag":"ABX9TyO/97lk+Y5oSluJTywTAf55"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"znzQDRXQe35Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734071905686,"user_tz":-540,"elapsed":2878,"user":{"displayName":"이지민","userId":"17530294469746342616"}},"outputId":"493f5274-d9ea-4e6e-c26d-6bbb63398745"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install gymnasium\n","!pip install ale-py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LnWY_F9nfgoI","executionInfo":{"status":"ok","timestamp":1734071915330,"user_tz":-540,"elapsed":9649,"user":{"displayName":"이지민","userId":"17530294469746342616"}},"outputId":"d1e1b3c3-72a2-491b-b76e-dcbbe9d6e1f9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: ale-py in /usr/local/lib/python3.10/dist-packages (0.10.1)\n","Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.10/dist-packages (from ale-py) (1.26.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py) (4.12.2)\n"]}]},{"cell_type":"code","source":["import os\n","import gymnasium as gym\n","import ale_py\n","gym.register_envs(ale_py)\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from PIL import Image\n","from gymnasium.utils.save_video import save_video\n","\n","import copy\n","import random\n","import time"],"metadata":{"id":"1Vq4LmqPhtOi","executionInfo":{"status":"ok","timestamp":1734071917861,"user_tz":-540,"elapsed":2540,"user":{"displayName":"이지민","userId":"17530294469746342616"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/Colab Notebooks/gymnasium/atari')"],"metadata":{"id":"jNnzGbOGhq7m","executionInfo":{"status":"ok","timestamp":1734071917862,"user_tz":-540,"elapsed":8,"user":{"displayName":"이지민","userId":"17530294469746342616"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tEIcfmTdewOB","executionInfo":{"status":"ok","timestamp":1734071917862,"user_tz":-540,"elapsed":7,"user":{"displayName":"이지민","userId":"17530294469746342616"}}},"outputs":[],"source":["class Breakout(gym.Wrapper):\n","    def __init__(self, render_mode='rgb_array_list', repeat=4, device='cpu'):\n","        env = gym.make('ALE/Breakout-v5', render_mode=render_mode, frameskip=1, repeat_action_probability=0.0)\n","        super(Breakout, self).__init__(env)\n","\n","        self.image_shape = (84,84)\n","        self.repeat = repeat\n","        self.lives = 5\n","        self.frame_buffer = []\n","        self.device = device\n","\n","    def step(self, action):\n","        total_reward = 0\n","        done = False\n","\n","        for i in range(self.repeat):\n","            observation, reward, done, truncacted, info = self.env.step(action)\n","\n","            total_reward += reward\n","\n","            current_lives = info['lives']\n","\n","            if current_lives < self.lives:\n","                total_reward = total_reward - 1\n","                self.lives = current_lives\n","\n","            self.frame_buffer.append(observation)\n","\n","            if done:\n","                break\n","\n","        max_frame = np.max(self.frame_buffer[-2:], axis=0)\n","        max_frame = self.process_observation(max_frame)\n","        max_frame = max_frame.to(self.device)\n","\n","        total_reward = torch.tensor(total_reward).view(1,-1).float()\n","        total_reward = total_reward.to(self.device)\n","\n","        done = torch.tensor(done).view(1,-1)\n","        done = done.to(self.device)\n","\n","        return max_frame, total_reward, done, info, observation\n","\n","    def reset(self):\n","        self.frame_buffer = []\n","\n","        observation, _ = self.env.reset()\n","        image = observation.copy()\n","\n","        self.lives = 5\n","\n","        observation = self.process_observation(observation)\n","\n","        return observation, image\n","\n","    def process_observation(self, observation):\n","        img = Image.fromarray(observation).resize(self.image_shape).convert(\"L\")\n","        img = torch.from_numpy(np.array(img))\n","        img = img.unsqueeze(0).unsqueeze(0)\n","        img = img.to(self.device)\n","\n","        return img/255.0\n","\n","class ReplayMemory:\n","    def __init__(self, capacity, device='cpu'):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.device = device\n","\n","    def insert(self, transition):\n","        transition = [item.to('cpu') for item in transition]\n","\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(transition)\n","        else:\n","            self.memory.remove(self.memory[0])\n","            self.memory.append(transition)\n","\n","    def sample(self, batch_size=64):\n","        batch = random.sample(self.memory, batch_size)\n","        batch = zip(*batch)\n","        return [torch.cat(items).to(self.device) for items in batch]\n","\n","    def can_sample(self, batch_size):\n","        return len(self.memory) >= batch_size * 10\n","\n","class Model(nn.Module):\n","    def __init__(self, nb_action=4):\n","        super(Model, self).__init__()\n","        self.conv1 = nn.Conv2d(1,32,kernel_size=(8,8), stride=(4,4))\n","        self.conv2 = nn.Conv2d(32,64,kernel_size=(4,4), stride=(2,2))\n","        self.conv3 = nn.Conv2d(64,64,kernel_size=(3,3), stride=(1,1))\n","\n","        self.action_value1 = nn.Linear(3136, 1024)\n","        self.action_value2 = nn.Linear(1024, 1024)\n","        self.action_value3 = nn.Linear(1024, nb_action)\n","\n","        self.state_value1 = nn.Linear(3136, 1024)\n","        self.state_value2 = nn.Linear(1024, 1024)\n","        self.state_value3 = nn.Linear(1024, 1)\n","\n","        self.relu = nn.ReLU()\n","        self.flatten = nn.Flatten()\n","        self.dropout = nn.Dropout(p=0.2)\n","\n","    def forward(self, x):\n","        x = torch.Tensor(x)\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.flatten(x)\n","\n","        s = self.dropout(self.relu(self.state_value1(x)))\n","        s = self.dropout(self.relu(self.state_value2(s)))\n","        s = self.relu(self.state_value3(s))\n","\n","        a = self.dropout(self.relu(self.action_value1(x)))\n","        a = self.dropout(self.relu(self.action_value2(a)))\n","        a = self.relu(self.action_value3(a))\n","\n","        output = s + (a - a.mean())\n","\n","        return output\n","\n","    def save_the_model(self, weights_filename='models/latest.pt'):\n","        if not os.path.exists(\"models\"):\n","            os.makedirs(\"models\")\n","        torch.save(self.state_dict(), weights_filename)\n","\n","    def load_the_model(self, weights_filename='models/latest.pt'):\n","        try:\n","            self.load_state_dict(torch.load(weights_filename, map_location=device))\n","            print(\"Loaded weights file\")\n","        except:\n","            print(\"No weights file\")\n","\n","def f(episode_id: int) -> bool:\n","    return True\n","\n","class Agent:\n","    def __init__(self, model, device='cpu', epsilon=1.0, min_epsilon=0.1, action_size=None, learning_rate=1e-5):\n","        self.memory = ReplayMemory(device=device, capacity=600000)\n","        self.model = model\n","        self.target_model = copy.deepcopy(model).eval()\n","        self.epsilon = epsilon\n","        self.min_epsilon = min_epsilon\n","        self.epsilon_decay = 1 - (((epsilon - min_epsilon) / 5000) * 2)\n","        self.batch_size = 64\n","        self.model.to(device)\n","        self.target_model.to(device)\n","        self.gamma = 0.99\n","        self.action_size = action_size\n","\n","        self.optimizer = optim.AdamW(model.parameters(),lr=learning_rate)\n","\n","    def get_action(self, state):\n","        if torch.rand(1) < self.epsilon:\n","            return torch.randint(self.action_size, (1,1)), None\n","        else:\n","            av = self.model(state).detach()\n","            return torch.argmax(av, dim=1, keepdim=True), av\n","\n","    def train(self, env, epochs):\n","        reward_list = {}\n","        for epoch in range(1,epochs + 1):\n","            print(epoch)\n","            reward_list[epoch] = 0\n","            state,_ = env.reset()\n","            done = False\n","\n","            while not done:\n","                action, _ = self.get_action(state)\n","\n","                next_state, reward, done, info, _ = env.step(action)\n","                reward_list[epoch] += reward\n","                self.memory.insert([state, action, reward, done, next_state])\n","\n","                if self.memory.can_sample(self.batch_size):\n","                    state_b, action_b, reward_b, done_b, next_state_b = self.memory.sample(self.batch_size)\n","                    qsa_b = self.model(state_b).gather(1,action_b)\n","                    next_qsa_b = self.target_model(next_state_b)\n","                    next_qsa_b = torch.max(next_qsa_b, dim=-1, keepdim=True)[0]\n","                    target_b = reward_b + ~done_b * self.gamma * next_qsa_b\n","                    loss = F.mse_loss(qsa_b, target_b)\n","                    self.model.zero_grad()\n","                    loss.backward()\n","                    self.optimizer.step()\n","\n","                state = next_state\n","\n","            if self.epsilon > self.min_epsilon:\n","                self.epsilon = self.epsilon * self.epsilon_decay\n","\n","            if epoch % 10 == 0:\n","                self.model.save_the_model()\n","                reward_sum = 0\n","                for i in range(10):\n","                    reward_sum += reward_list[epoch - i]\n","                print(reward_sum/10)\n","\n","            if epoch % 100 == 0:\n","                self.target_model.load_state_dict(self.model.state_dict())\n","\n","                save_video(\n","                env.render(),\n","                \"videos\",\n","                episode_trigger=f,\n","                fps=24,\n","                step_starting_index=0,\n","                episode_index=epoch)\n","\n","            if epoch % 1000 == 0:\n","                self.model.save_the_model(f\"models/model_iter_{epoch}.pt\")"]},{"cell_type":"code","source":["os.environ['KMP_DUPLICATE_OK'] = 'TRUE'\n","device = torch.device('cuda:0')\n","\n","environment = Breakout(device=device)\n","\n","model = Model(nb_action=4).to(device)\n","\n","agent = Agent(model=model,\n","              device=device,\n","              epsilon=1,\n","              action_size=4,\n","              learning_rate=1e-5)\n","\n","agent.train(env=environment, epochs=10000000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8ysMdLkxhxd4","executionInfo":{"status":"error","timestamp":1734073319203,"user_tz":-540,"elapsed":1401347,"user":{"displayName":"이지민","userId":"17530294469746342616"}},"outputId":"bcee92d2-b0c8-4de3-bb81-c216baac5975"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","tensor([[-3.9000]], device='cuda:0')\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","tensor([[-4.]], device='cuda:0')\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","tensor([[-3.3000]], device='cuda:0')\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","tensor([[-3.5000]], device='cuda:0')\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","tensor([[-4.]], device='cuda:0')\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","tensor([[-4.3000]], device='cuda:0')\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","tensor([[-3.2000]], device='cuda:0')\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","tensor([[-3.9000]], device='cuda:0')\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","tensor([[-4.1000]], device='cuda:0')\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","tensor([[-3.8000]], device='cuda:0')\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","tensor([[-3.1000]], device='cuda:0')\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","tensor([[-4.2000]], device='cuda:0')\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","tensor([[-3.7000]], device='cuda:0')\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","tensor([[-3.4000]], device='cuda:0')\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","tensor([[-3.8000]], device='cuda:0')\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","tensor([[-3.4000]], device='cuda:0')\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","tensor([[-3.6000]], device='cuda:0')\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","tensor([[-3.8000]], device='cuda:0')\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","tensor([[-4.2000]], device='cuda:0')\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","tensor([[-3.7000]], device='cuda:0')\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","tensor([[-4.]], device='cuda:0')\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","tensor([[-3.5000]], device='cuda:0')\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","tensor([[-3.9000]], device='cuda:0')\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","tensor([[-3.8000]], device='cuda:0')\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","tensor([[-3.2000]], device='cuda:0')\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","tensor([[-3.7000]], device='cuda:0')\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","tensor([[-4.]], device='cuda:0')\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","tensor([[-3.4000]], device='cuda:0')\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","tensor([[-4.5000]], device='cuda:0')\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","tensor([[-3.7000]], device='cuda:0')\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","tensor([[-4.]], device='cuda:0')\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","tensor([[-3.9000]], device='cuda:0')\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","tensor([[-3.4000]], device='cuda:0')\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","tensor([[-2.9000]], device='cuda:0')\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","tensor([[-3.8000]], device='cuda:0')\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","tensor([[-4.1000]], device='cuda:0')\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","tensor([[-4.3000]], device='cuda:0')\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","tensor([[-4.4000]], device='cuda:0')\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","tensor([[-3.9000]], device='cuda:0')\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","tensor([[-4.2000]], device='cuda:0')\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","tensor([[-3.9000]], device='cuda:0')\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","tensor([[-4.4000]], device='cuda:0')\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","tensor([[-3.5000]], device='cuda:0')\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","tensor([[-3.9000]], device='cuda:0')\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","tensor([[-3.8000]], device='cuda:0')\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","tensor([[-4.7000]], device='cuda:0')\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","tensor([[-3.8000]], device='cuda:0')\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","tensor([[-3.9000]], device='cuda:0')\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","tensor([[-4.2000]], device='cuda:0')\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","tensor([[-4.5000]], device='cuda:0')\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","tensor([[-4.5000]], device='cuda:0')\n","511\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","tensor([[-4.]], device='cuda:0')\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","tensor([[-4.]], device='cuda:0')\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-6784500fd529>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m               learning_rate=1e-5)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-9ccbe90d5364>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env, epochs)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0mreward_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-9ccbe90d5364>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmax_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmax_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mmax_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-9ccbe90d5364>\u001b[0m in \u001b[0;36mprocess_observation\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 )\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m     def reduce(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}